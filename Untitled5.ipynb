{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9c8rG7s81Sw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sn\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D, LeakyReLU\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import time\n",
        "import os\n",
        "from PIL import Image\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim = (176,208)\n",
        "test_split_percent = .1\n",
        "validation_split_percent = .2\n",
        "zoom = [.99,1.01]\n",
        "bright_range = [.8,1.2]\n",
        "layers_unlocked = True\n",
        "lr = 0.0001\n",
        "batch = 20\n",
        "eps = 20\n",
        "momentum = .9\n",
        "save_model_name = \"val%2d_epochs%d\"%(validation_split_percent*100,eps)\n",
        "print(save_model_name)"
      ],
      "metadata": {
        "id": "TyMrvXgGI0IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dr = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,fill_mode='constant',cval=0, brightness_range=bright_range,zoom_range=zoom,data_format='channels_last',zca_whitening=False)\n",
        "train_data_gen = train_dr.flow_from_directory(directory=\"/content/drive/MyDrive/Alzheimer_s Dataset/train/\",target_size=dim, batch_size=5000)\n",
        "\n",
        "test_dr = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,fill_mode='constant',cval=0,zoom_range=[1,1],data_format='channels_last')\n",
        "test_data_gen = test_dr.flow_from_directory(directory=\"/content/drive/MyDrive/Alzheimer_s Dataset/test\",target_size=dim,batch_size=5000, shuffle = False)"
      ],
      "metadata": {
        "id": "UoWGyoCAI0K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,train_labels =  train_data_gen.next()\n",
        "test_data,test_labels = test_data_gen.next()"
      ],
      "metadata": {
        "id": "zZ1f9UUiI0Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(direction):\n",
        "    list_dir=os.listdir(direction)\n",
        "    plt.figure(figsize=(14,8))\n",
        "    for i in range(1,7):\n",
        "        plt.subplot(2,3,i)\n",
        "        img= plt.imread(os.path.join(direction,list_dir[i]))\n",
        "        plt.imshow(img,cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "\n",
        "MildDemented_dir= '/content/drive/MyDrive/Alzheimer_s Dataset/test/MildDemented'\n",
        "visualize(MildDemented_dir)"
      ],
      "metadata": {
        "id": "OWvgLX5OI0PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data = np.concatenate((train_data,test_data))\n",
        "total_labels = np.concatenate((train_labels,test_labels))\n",
        "print(total_data.shape)\n",
        "print(total_labels.shape)"
      ],
      "metadata": {
        "id": "-6lOBtSGI0RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_split = test_split_percent+validation_split_percent\n",
        "test_val_split = test_split_percent/initial_split\n",
        "train_data, test_val_data, train_labels, test_val_labels = train_test_split(total_data,total_labels,test_size=initial_split)\n",
        "test_data, val_data, test_labels, val_labels = train_test_split(test_val_data,test_val_labels,test_size=test_val_split)\n",
        "\n",
        "print('train: ',train_data.shape)\n",
        "print('validation',val_data.shape)\n",
        "print('test',test_data.shape)"
      ],
      "metadata": {
        "id": "K8uW04dCI0TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(train_labels.shape)\n",
        "print(val_data.shape)\n",
        "print(val_labels.shape)\n",
        "print(test_data.shape)\n",
        "print(test_labels.shape)"
      ],
      "metadata": {
        "id": "vsUQVz5gI0Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(221)\n",
        "plt.imshow(train_data[1,:,:,:])\n",
        "plt.subplot(222)\n",
        "plt.imshow(train_data[2,:,:,:])\n",
        "plt.subplot(223)\n",
        "plt.imshow(val_data[3,:,:,:])\n",
        "plt.subplot(224)\n",
        "plt.imshow(val_data[4,:,:,:])\n",
        "plt.show()\n",
        "plt.subplot(221)\n",
        "plt.imshow(test_data[5,:,:,:])\n",
        "plt.subplot(222)\n",
        "plt.imshow(test_data[154,:,:,:])"
      ],
      "metadata": {
        "id": "oKyUsnUXI0Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.amax(train_data))\n",
        "print(np.amin(train_data))\n",
        "print(np.amax(val_data))\n",
        "print(np.amin(val_data))"
      ],
      "metadata": {
        "id": "EBUE5uc7JGQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(141)\n",
        "plt.imshow(train_data[3,:,:,0])\n",
        "plt.subplot(142)\n",
        "plt.imshow(train_data[3,:,:,1])\n",
        "plt.subplot(143)\n",
        "plt.imshow(train_data[3,:,:,2])\n",
        "plt.subplot(144)\n",
        "plt.imshow(train_data[3,:,:,:])"
      ],
      "metadata": {
        "id": "9KrbkwerJGTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vg_model = tf.keras.applications.vgg16.VGG16(include_top=False,input_shape=(dim[0],dim[1],3), pooling = 'max')"
      ],
      "metadata": {
        "id": "HcI-2hGsJGXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vg_model.get_layer('block1_conv1').trainable = layers_unlocked\n",
        "vg_model.get_layer('block1_conv2').trainable = layers_unlocked\n",
        "vg_model.get_layer('block2_conv1').trainable = layers_unlocked\n",
        "vg_model.get_layer('block2_conv2').trainable = layers_unlocked\n",
        "vg_model.get_layer('block3_conv1').trainable = layers_unlocked\n",
        "vg_model.get_layer('block3_conv2').trainable = layers_unlocked\n",
        "vg_model.get_layer('block3_conv3').trainable = layers_unlocked\n",
        "vg_model.get_layer('block4_conv1').trainable = layers_unlocked\n",
        "vg_model.get_layer('block4_conv2').trainable = layers_unlocked\n",
        "vg_model.get_layer('block4_conv3').trainable = layers_unlocked\n",
        "flat = Flatten()(vg_model.output)\n",
        "fc1 = Dense(1024,activation='relu', kernel_initializer='he_uniform')(flat)\n",
        "dp1 = Dropout(0.25)(fc1)\n",
        "output = Dense(4,activation='softmax')(dp1)\n",
        "vg_model = Model(inputs=vg_model.inputs, outputs=output)\n",
        "\n",
        "vg_model.summary()"
      ],
      "metadata": {
        "id": "0G-dmtoiJGZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.SGD(learning_rate=lr, momentum=momentum, nesterov=True,name='SGD')\n",
        "vg_model.compile(optimizer=opt, loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xeO31hTHJGcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_history = vg_model.fit(train_data,train_labels,validation_data=(val_data,val_labels),epochs=eps,batch_size=batch, shuffle=True)\n",
        "#scores = vg_model.evaluate(train_data, train_labels)\n",
        "#print(\"Accuracy: %.2f%%\" %(scores[1]*100))"
      ],
      "metadata": {
        "id": "vBf3zrtdJPCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vg_model.save(\"model_new.h5\")"
      ],
      "metadata": {
        "id": "kCbw848gJPGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.title('Accuracy per Epoch')\n",
        "plt.plot(np.linspace(1,eps,num=eps),model_history.history['acc'], label = 'Training Accuracy')\n",
        "plt.plot(np.linspace(1,eps,num=eps),model_history.history['val_acc'], label = 'Validation Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.title('Loss per Epoch')\n",
        "plt.plot(np.linspace(1,eps,num=eps),model_history.history['loss'], label = 'Training Loss')\n",
        "plt.plot(np.linspace(1,eps,num=eps),model_history.history['val_loss'], label = 'Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print('image dimensions: ',dim)\n",
        "print('validation split percentage: ',validation_split_percent)\n",
        "print('zoom: ',zoom)\n",
        "print('Learning Rate: ',lr)\n",
        "print('batch size: ',batch)\n",
        "print('epochs: ',eps)\n",
        "print('brightness range: ',bright_range)\n",
        "print('Model trained from scratch? : ',layers_unlocked)\n",
        "end = time.time()\n",
        "print('Total Time Elapsed = %.2d minutes'%((end - start)/60))"
      ],
      "metadata": {
        "id": "LuIWMrzPJPKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vg_model = load_model(\"/content/drive/MyDrive/model_new.h5\")"
      ],
      "metadata": {
        "id": "TctW6imQJPMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_scores = vg_model.evaluate(train_data, train_labels)\n",
        "val_scores = vg_model.evaluate(val_data,val_labels)\n",
        "test_scores = vg_model.evaluate(test_data, test_labels)\n",
        "\n",
        "print('Train Accuracy: %.2f%%'%(train_scores[1]*100))\n",
        "print('Validation Accuracy: %.2f%%'%(val_scores[1]*100))\n",
        "print('Test Accuracy: %.2f%%'%(test_scores[1]*100))"
      ],
      "metadata": {
        "id": "iDqI5dtrMitP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "predic = vg_model.predict(test_data)\n",
        "predic = np.argmax(predic, axis=1)\n",
        "labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "conf_arr = confusion_matrix(labels, predic)\n",
        "\n",
        "plt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "ax = sns.heatmap(conf_arr, cmap='Blues', annot=True, fmt='d', xticklabels=['MildDementia', 'ModerateDementia', 'NonDementia', 'VeryMildDementia'],\n",
        "                 yticklabels=['MildDementia', 'ModerateDementia', 'NonDementia', 'VeryMildDementia'])\n",
        "plt.title('Alzheimer\\'s Diagnosis')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Truth')\n",
        "plt.show(ax)\n",
        "plt.savefig(\"confusion_matrix.png\")\n",
        "\n",
        "class_report = classification_report(labels, predic, target_names=['MildDementia', 'ModerateDementia', 'NonDementia', 'VeryMildDementia'])\n",
        "print(\"Classification Report:\\n\", class_report)\n"
      ],
      "metadata": {
        "id": "DQo0nmTJJPO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "precision = np.diag(conf_arr) / np.sum(conf_arr, axis=0)\n",
        "recall = np.diag(conf_arr) / np.sum(conf_arr, axis=1)\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "class_names=['MildDementia', 'ModerateDementia', 'NonDementia', 'VeryMildDementia']\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(class_names, precision, marker='o', label='Precision', color='green')\n",
        "plt.title('Precision for Each Class')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Precision Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.savefig(\"precision_line_plot.png\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(class_names, recall, marker='o', label='Recall', color='blue')\n",
        "plt.title('Recall for Each Class')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Recall Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.savefig(\"recall_line_plot.png\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(class_names, f1_score, marker='o', label='F1 Score', color='orange')\n",
        "plt.title('F1 Score for Each Class')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.savefig(\"f1_score_line_plot.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hSodRtitJPSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "predic = vg_model.predict(test_data)\n",
        "labels = label_binarize(np.argmax(test_labels, axis=1), classes=[0, 1, 2, 3])\n",
        "predic = label_binarize(np.argmax(predic, axis=1), classes=[0, 1, 2, 3])\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(labels.shape[1]):\n",
        "    fpr[i], tpr[i], _ = roc_curve(labels[:, i], predic[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "for i in range(labels.shape[1]):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Multi-Class Classification')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I0dttSlkJg3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IXXrc0CvJg5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "llGFikVAJg76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "CLASSES = {0: \"Mild Dementia\", 1: \"Moderate Dementia\", 2: \"Non Dementia\", 3: \"Very Mild Dementia\"}\n",
        "\n",
        "new_image_path = \"/content/drive/MyDrive/Alzheimer_s Dataset/test/MildDemented/26 (19).jpg\"\n",
        "new_img = image.load_img(new_image_path, target_size=dim)\n",
        "new_img_array = image.img_to_array(new_img)\n",
        "new_img_array = np.expand_dims(new_img_array, axis=0)\n",
        "new_img_array = preprocess_input(new_img_array)\n",
        "\n",
        "predictions = vg_model.predict(new_img_array)\n",
        "predicted_class = np.argmax(predictions)\n",
        "pred_class_label = CLASSES[predicted_class]\n",
        "\n",
        "print(\"Predicted class:\", pred_class_label)\n"
      ],
      "metadata": {
        "id": "S-iNnyEnJg-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wQeBntrpJhAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iwEIY6aOI0aF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}